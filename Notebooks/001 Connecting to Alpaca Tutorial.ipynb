{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Make sure you Alpaca credentials are being read properly and you are connecting to Alpaca"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Standard libraries\n",
    "from datetime import datetime, timedelta\n",
    "import time\n",
    "import sys\n",
    "\n",
    "# Non-standard libraries\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "\n",
    "# Alpaca API\n",
    "from alpaca_trade_api.rest import REST\n",
    "\n",
    "# Suppress warnings\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "# Project-specific imports\n",
    "sys.path.append(r\"d:\\dev\\stat_656_autotrader\")\n",
    "from credentials import API_KEY, SECRET_KEY, ENDPOINT_URL "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Remove the '#' and uncomment the code to print your credentials from the .secrets file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#print(f\"API_KEY: {API_KEY}, SECRET_KEY: {SECRET_KEY}, ENDPOINT_URL: {ENDPOINT_URL}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Connect to Alpaca"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize Alpaca REST client\n",
    "try:\n",
    "    alpaca = REST(API_KEY, SECRET_KEY, base_url=ENDPOINT_URL)\n",
    "    print(\"Connected to Alpaca successfully!\")\n",
    "\n",
    "except Exception as e:\n",
    "    print(f\"Connection failed: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get a list of all Alpaca stock tickers traded on (NASDAQ, NYSE, AMEX)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# API call for Alpaca assets\n",
    "assets = alpaca.list_assets(status='active')  # Consider only active assets\n",
    "\n",
    "# All US exchanges (NASDAQ, NYSE)\n",
    "us_exchanges = ['NASDAQ', 'NYSE', 'AMEX']\n",
    "\n",
    "# Filter to company stocks only (Uppercase letters only, no numbers, periods, underscores, lowercase)\n",
    "stock_assets = [\n",
    "    asset for asset in assets\n",
    "    if asset.exchange in us_exchanges\n",
    "    and asset.tradable\n",
    "    and asset.status == 'active'\n",
    "    and asset.symbol.isalpha()\n",
    "    and asset.symbol.isupper()\n",
    "]\n",
    "\n",
    "stock_tickers = [asset.symbol for asset in stock_assets]\n",
    "\n",
    "print(f\"Fetched {len(stock_tickers)} company stock tickers from Alpaca (U.S. exchanges, no CUSIPs/ETFs/SPACs)!\")\n",
    "print(\"First 20 company stock tickers:\", stock_tickers[:20])\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test the fetch time for Alpaca"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "years_back = 5  # Number of years of historical data required\n",
    "start_date = \"2002-01-01\"  # Start date for data fetching\n",
    "end_date = (datetime.now() - timedelta(days=1)).strftime(\"%Y-%m-%d\")  # End date (yesterday)\n",
    "trading_days_back = years_back * 252  # Approximate number of trading days per year (252)\n",
    "\n",
    "print(f\"Fetching OHLC from {start_date} to {end_date} (~threshold: {trading_days_back} days)\")\n",
    "\n",
    "# Initialize dataframe and performance tracking variables\n",
    "alpaca_df = pd.DataFrame()\n",
    "start_time = time.time()\n",
    "missing_data_count = 0  # Counter for tickers with no data\n",
    "not_enough_time_count = 0  # Counter for tickers with insufficient data\n",
    "processed_ticker_count = 0  # Counter for processed tickers\n",
    "subset_size = 175  # Number of tickers to process in this run\n",
    "subset_tickers = stock_tickers[:subset_size]  # Select the first 50 tickers\n",
    "\n",
    "# Loop through each ticker to fetch historical stock data from Alpaca\n",
    "for ticker in tqdm(subset_tickers, desc=\"Alpaca Download Progress\"):\n",
    "    try:\n",
    "        processed_ticker_count += 1  # Increment the processed ticker counter\n",
    "        bars = alpaca.get_bars(ticker, \"1Day\", start_date, end_date).df  # Fetch daily OHLC data\n",
    "\n",
    "        # Check if any data was retrieved\n",
    "        if not bars.empty:\n",
    "            # Extract relevant OHLC data and reset the DataFrame index\n",
    "            df = bars[['open', 'high', 'low', 'close']].reset_index()\n",
    "\n",
    "            # Check if retrieved data covers the required number of years\n",
    "            if len(df) < trading_days_back:\n",
    "                missing_data_count += 1\n",
    "                not_enough_time_count += 1\n",
    "\n",
    "                #print(f\"Not enough trading days. Skipped {ticker} (~{len(df)} < {trading_days_back} days)\")\n",
    "                continue\n",
    "\n",
    "            # Add ticker and formatted date columns for clarity\n",
    "            df['ticker'] = ticker\n",
    "            df['date'] = df['timestamp'].dt.strftime(\"%Y-%m-%d\")\n",
    "\n",
    "            # Reorder columns\n",
    "            df = df[['ticker', 'date', 'open', 'high', 'low', 'close']]\n",
    "\n",
    "            # Append this ticker's data to the main DataFrame\n",
    "            alpaca_df = pd.concat([alpaca_df, df])\n",
    "        else:\n",
    "            # If no data was retrieved, increment the missing data counter\n",
    "            missing_data_count += 1\n",
    "            print(f\"No data for {ticker}\")\n",
    "\n",
    "        # Wait briefly to prevent API rate limiting\n",
    "        time.sleep(1)\n",
    "\n",
    "    except Exception as e:\n",
    "        # Handle and log any exceptions during data retrieval\n",
    "        print(f\"Error for {ticker}: {e}\")\n",
    "        time.sleep(1)\n",
    "\n",
    "# Calculate total processing time and performance metrics\n",
    "total_seconds = time.time() - start_time\n",
    "seconds_per_ticker = round((total_seconds / len(subset_tickers)), 2)\n",
    "estimated_total_time = round(seconds_per_ticker * len(stock_tickers) / 60)\n",
    "\n",
    "# Output performance summary and sample data\n",
    "print(f\"\\nFetched {len(alpaca_df)} rows of stock data in {total_seconds:.2f} seconds.\")\n",
    "print(f\"Processed {processed_ticker_count} tickers, missing {missing_data_count} tickers, {not_enough_time_count} tickers did not have enough time.\")\n",
    "print(f\"Processing time per ticker: {seconds_per_ticker:.2f} seconds. Estimated processing time for all stocks in the dataset: {estimated_total_time} minutes.\")\n",
    "print(\"\\nExample Table Data:\\n\")\n",
    "print(\"Alpaca Sample:\", display(alpaca_df.head(30)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "aaron_dev",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
