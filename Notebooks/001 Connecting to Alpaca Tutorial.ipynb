{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Testing Data Fetch Time and Alpaca Connection. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Standard libraries\n",
    "from datetime import datetime, timedelta\n",
    "import time\n",
    "import sys\n",
    "\n",
    "# Non-standard libraries\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "\n",
    "# Alpaca API\n",
    "from alpaca_trade_api.rest import REST\n",
    "import yf\n",
    "# Suppress warnings\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "# Project-specific imports\n",
    "sys.path.append(r\"d:\\dev\\stat_656_autotrader\")\n",
    "from credentials import ALPACA_API_KEY, ALPACA_SECRET_KEY, ALPAKA_ENDPOINT_URL"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Remove the '#' and uncomment the code to print your credentials from the .secrets file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#print(f\"API_KEY: {API_KEY}, SECRET_KEY: {SECRET_KEY}, ENDPOINT_URL: {ENDPOINT_URL}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Connect to Alpaca"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize Alpaca REST client\n",
    "try:\n",
    "    alpaca = REST(ALPACA_API_KEY, ALPACA_SECRET_KEY, base_url=ALPAKA_ENDPOINT_URL)\n",
    "    print(\"Connected to Alpaca successfully!\")\n",
    "\n",
    "except Exception as e:\n",
    "    print(f\"Connection failed: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get a list of all Alpaca stock tickers traded on (NASDAQ, NYSE, AMEX)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# API call for Alpaca assets\n",
    "assets = alpaca.list_assets(status='active')  # Consider only active assets\n",
    "\n",
    "# All US exchanges (NASDAQ, NYSE)\n",
    "us_exchanges = ['NASDAQ', 'NYSE', 'AMEX']\n",
    "\n",
    "# Filter to company stocks only (Uppercase letters only, no numbers, periods, underscores, lowercase)\n",
    "stock_assets = [\n",
    "    asset for asset in assets\n",
    "    if asset.exchange in us_exchanges\n",
    "    and asset.tradable\n",
    "    and asset.status == 'active'\n",
    "    and asset.symbol.isalpha()\n",
    "    and asset.symbol.isupper()\n",
    "]\n",
    "\n",
    "stock_tickers = [asset.symbol for asset in stock_assets]\n",
    "\n",
    "print(f\"Fetched {len(stock_tickers)} company stock tickers from Alpaca (U.S. exchanges, no CUSIPs/ETFs/SPACs)!\")\n",
    "print(\"First 20 company stock tickers:\", stock_tickers[:20])\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Configure Variables for the Tests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "years_back = 5  # Number of years of historical data required\n",
    "subset_size = 175  # Number of tickers to process in this run\n",
    "subset_tickers = stock_tickers[:subset_size]  # Select the first 50 tickers\n",
    "start_date = \"2002-01-01\"  # Start date for data fetching\n",
    "\n",
    "# End date for data fetching\n",
    "end_date = (datetime.now() - timedelta(days=1)).strftime(\"%Y-%m-%d\")  # End date (yesterday)\n",
    "trading_days_back = years_back * 252  # Approximate number of trading days per year (252)\n",
    "print(f\"Fetching OHLC from {start_date} to {end_date} (~threshold: {trading_days_back} days)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test the fetch time for Alpaca for all assets in the NASDAQ, NYSE, and AMEX"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize dataframe and performance tracking variables\n",
    "alpaca_df = pd.DataFrame()\n",
    "start_time = time.time()\n",
    "missing_data_count = 0  # Counter for tickers with no data\n",
    "not_enough_time_count = 0  # Counter for tickers with insufficient data\n",
    "processed_ticker_count = 0  # Counter for processed tickers\n",
    "\n",
    "# Loop through each ticker to fetch historical stock data from Alpaca\n",
    "for ticker in tqdm(subset_tickers, desc=\"Alpaca Download Progress\"):\n",
    "    try:\n",
    "        processed_ticker_count += 1  # Increment the processed ticker counter\n",
    "        bars = alpaca.get_bars(ticker, \"1Day\", start_date, end_date).df  # Fetch daily OHLC data\n",
    "\n",
    "        # Check if any data was retrieved\n",
    "        if not bars.empty:\n",
    "            # Extract relevant OHLC data and reset the DataFrame index\n",
    "            df = bars[['open', 'high', 'low', 'close']].reset_index()\n",
    "\n",
    "            # Check if retrieved data covers the required number of years\n",
    "            if len(df) < trading_days_back:\n",
    "                missing_data_count += 1\n",
    "                not_enough_time_count += 1\n",
    "\n",
    "                #print(f\"Not enough trading days. Skipped {ticker} (~{len(df)} < {trading_days_back} days)\")\n",
    "                continue\n",
    "\n",
    "            # Add ticker and formatted date columns for clarity\n",
    "            df['ticker'] = ticker\n",
    "            df['date'] = df['timestamp'].dt.strftime(\"%Y-%m-%d\")\n",
    "\n",
    "            # Reorder columns\n",
    "            df = df[['ticker', 'date', 'open', 'high', 'low', 'close']]\n",
    "\n",
    "            # Append this ticker's data to the main DataFrame\n",
    "            alpaca_df = pd.concat([alpaca_df, df])\n",
    "        else:\n",
    "            # If no data was retrieved, increment the missing data counter\n",
    "            missing_data_count += 1\n",
    "            print(f\"No data for {ticker}\")\n",
    "\n",
    "        # Wait briefly to prevent API rate limiting\n",
    "        time.sleep(1)\n",
    "\n",
    "    except Exception as e:\n",
    "        # Handle and log any exceptions during data retrieval\n",
    "        print(f\"Error for {ticker}: {e}\")\n",
    "        time.sleep(1)\n",
    "\n",
    "# Calculate total processing time and performance metrics\n",
    "total_seconds = time.time() - start_time\n",
    "seconds_per_ticker = round((total_seconds / len(subset_tickers)), 2)\n",
    "estimated_total_time = round(seconds_per_ticker * len(stock_tickers) / 60)\n",
    "\n",
    "# Output performance summary and sample data\n",
    "print(f\"\\nFetched {len(alpaca_df)} rows of stock data in {total_seconds:.2f} seconds.\")\n",
    "print(f\"Processed {processed_ticker_count} tickers, missing {missing_data_count} tickers, {not_enough_time_count} tickers did not have enough time.\")\n",
    "print(f\"Processing time per ticker: {seconds_per_ticker:.2f} seconds. Estimated processing time for all stocks in the dataset: {estimated_total_time} minutes.\")\n",
    "print(\"\\nExample Table Data:\\n\")\n",
    "print(\"Alpaca Sample:\", display(alpaca_df.head(30)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Testing the Fetch Time for Yesterday's (OHLC) (One Day Only)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "yesterday = (datetime.now() - timedelta(days=1)).strftime(\"%Y-%m-%d\") # RFC3339 format - date in the format required for Alpaca API\n",
    "\n",
    "start_time = time.time()  # Start timer for data fetching\n",
    "daily_df = pd.DataFrame()  # Initialize DataFrame to store OHLC data\n",
    "\n",
    "# Loop through tickers to fetch OHLC data for yesterday\n",
    "for ticker in tqdm(subset_tickers, desc=\"Fetching Yesterday's OHLC\"):\n",
    "    try:\n",
    "        bars = alpaca.get_bars(ticker, \"1Day\", yesterday, yesterday).df  # Fetch daily OHLC data for yesterday\n",
    "        \n",
    "        if not bars.empty:\n",
    "            bars.reset_index(inplace=True)  # Reset DataFrame index for convenience\n",
    "            ohlc = bars[['timestamp', 'open', 'high', 'low', 'close']]  # Extract relevant columns\n",
    "            ohlc['ticker'] = ticker  # Add ticker symbol\n",
    "            ohlc['date'] = ohlc['timestamp'].dt.strftime(\"%Y-%m-%d\")  # Format timestamp as date\n",
    "            daily_df = pd.concat([daily_df, ohlc[['ticker', 'date', 'open', 'high', 'low', 'close']]])  # Append to main DataFrame\n",
    "        else:\n",
    "            print(f\"No data for {ticker}\")  # Log if no data available for ticker\n",
    "\n",
    "        time.sleep(1)  # Brief pause to avoid API rate limits\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"Error fetching {ticker}: {e}\")  # Log any exceptions during fetch\n",
    "        time.sleep(1)\n",
    "\n",
    "fetch_time = time.time() - start_time  # Calculate total fetching time\n",
    "seconds_per_ticker = round((fetch_time / len(subset_tickers)), 2)  # Calculate average time per ticker\n",
    "estimated_total_time = round(seconds_per_ticker * len(stock_tickers) / 60)  # Estimate total time for all tickers in minutes\n",
    "\n",
    "# Output summary of fetch results\n",
    "print(f\"\\nFetched OHLC data for yesterday ({yesterday}) in {fetch_time:.2f} seconds.\")\n",
    "print(f\"Average processing time per ticker: {seconds_per_ticker:.2f} seconds.\")\n",
    "print(f\"Estimated total processing time for all stocks: {estimated_total_time} minutes.\")\n",
    "print(\"\\nSample fetched data:\")\n",
    "print(daily_df.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Testing the Fetch Time for the Open Prices ONLY in the Morning "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Today's date\n",
    "today = datetime.now().strftime(\"%Y-%m-%d\") # RFC3339 format - date in the format required for Alpaca API\n",
    "\n",
    "# Market opens at 9:30 AM EST (or EDT, depending on daylight savings)\n",
    "market_open = f\"{today}T09:30:00-05:00\"  \n",
    "market_open_dt = pd.Timestamp(market_open)\n",
    "\n",
    "start_time = time.time()\n",
    "open_prices_df = pd.DataFrame()\n",
    "\n",
    "# Loop to fetch today's opening prices for each ticker\n",
    "for ticker in tqdm(subset_tickers, desc=\"Fetching Today's Open Prices\"):\n",
    "    try:\n",
    "        # Fetching the first minute bar (market open price)\n",
    "        bars = alpaca.get_bars(\n",
    "            ticker, \n",
    "            \"1Min\", \n",
    "            market_open_dt.isoformat(), \n",
    "            (market_open_dt + timedelta(minutes=1)).isoformat()\n",
    "        ).df\n",
    "        \n",
    "        if not bars.empty:\n",
    "            bars.reset_index(inplace=True)\n",
    "            open_price = bars.iloc[0]['open']\n",
    "            \n",
    "            # Append opening price data to DataFrame\n",
    "            open_prices_df = pd.concat([\n",
    "                open_prices_df, \n",
    "                pd.DataFrame({\n",
    "                    'ticker': [ticker],\n",
    "                    'date': [today],\n",
    "                    'open': [open_price]\n",
    "                })\n",
    "            ])\n",
    "        # else:\n",
    "        #     print(f\"No open data for {ticker}\")\n",
    "\n",
    "        time.sleep(1)  # Pause to avoid API rate limits\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"Error fetching {ticker}: {e}\")\n",
    "        time.sleep(1)\n",
    "\n",
    "# Performance metrics\n",
    "fetch_time = time.time() - start_time\n",
    "seconds_per_ticker = round((fetch_time / len(subset_tickers)), 2)\n",
    "estimated_total_time = round(seconds_per_ticker * len(stock_tickers) / 60)\n",
    "\n",
    "print(f\"\\nFetched today's open prices ({today}) in {fetch_time:.2f} seconds.\")\n",
    "print(f\"Average processing time per ticker: {seconds_per_ticker:.2f} seconds.\")\n",
    "print(f\"Estimated total processing time for all stocks: {estimated_total_time} minutes.\\n\")\n",
    "\n",
    "print(open_prices_df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Batch Fetching for One Day"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get today's date in the format required for Alpaca API\n",
    "today = datetime.now().strftime(\"%Y-%m-%d\")\n",
    "market_open_dt = pd.Timestamp(f\"{today}T09:30:00-05:00\").isoformat()\n",
    "\n",
    "# Fetch real-time opening prices for multiple tickers simultaneously\n",
    "try:\n",
    "    bars = alpaca.get_latest_bars(subset_tickers)  # Passes subset_tickers list directly\n",
    "\n",
    "    # Parse results into a DataFrame\n",
    "    data = []\n",
    "    for ticker, bar in bars.items():\n",
    "        data.append({\n",
    "            'ticker': ticker,\n",
    "            'date': bar.t.strftime(\"%Y-%m-%d\"),\n",
    "            'open': bar.o,\n",
    "            'high': bar.h,\n",
    "            'low': bar.l,\n",
    "            'close': bar.c,\n",
    "            'volume': bar.v\n",
    "        })\n",
    "\n",
    "    real_time_df = pd.DataFrame(data)\n",
    "    print(\"Real-Time Opening Prices (Market Open):\")\n",
    "    print(real_time_df.head())\n",
    "\n",
    "except Exception as e:\n",
    "    print(f\"Error fetching real-time data: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "aaron_dev",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
