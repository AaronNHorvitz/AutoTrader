{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Make sure you Alpaca credentials are being read properly and you are connecting to Alpaca"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Standard libraries\n",
    "from datetime import datetime, timedelta\n",
    "import time\n",
    "import sys\n",
    "\n",
    "# Non-standard libraries\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "\n",
    "# Alpaca API\n",
    "from alpaca_trade_api.rest import REST\n",
    "\n",
    "# Suppress warnings\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "# Project-specific imports\n",
    "sys.path.append(r\"d:\\dev\\stat_656_autotrader\")\n",
    "from credentials import API_KEY, SECRET_KEY, ENDPOINT_URL "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Remove the '#' and uncomment the code to print your credentials from the .secrets file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#print(f\"API_KEY: {API_KEY}, SECRET_KEY: {SECRET_KEY}, ENDPOINT_URL: {ENDPOINT_URL}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Connect to Alpaca"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Connected to Alpaca successfully!\n"
     ]
    }
   ],
   "source": [
    "# Initialize Alpaca REST client\n",
    "try:\n",
    "    alpaca = REST(API_KEY, SECRET_KEY, base_url=ENDPOINT_URL)\n",
    "    print(\"Connected to Alpaca successfully!\")\n",
    "\n",
    "except Exception as e:\n",
    "    print(f\"Connection failed: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get a list of all Alpaca stock tickers traded on (NASDAQ, NYSE, AMEX)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fetched 7177 company stock tickers from Alpaca (U.S. exchanges, no CUSIPs/ETFs/SPACs)!\n",
      "First 150 company stock tickers: ['XHR', 'NXN', 'NXLIW', 'XIFR', 'NXL', 'ELC', 'ELBM', 'ELAB', 'IGI', 'IDAI', 'ICUCW', 'ICU', 'NXJ', 'EKSO', 'EKG', 'HTFC', 'HOVR', 'NXGLW', 'NXG', 'HIFS', 'XMTR', 'GRDN', 'GDSTR', 'XOM', 'GB', 'EIIA', 'FRHC', 'XP', 'XPEV', 'XPRO', 'XRX', 'EICC', 'NWTN', 'XYZ', 'FIVY', 'EICB', 'YELP', 'NWTG', 'YETI', 'EICA', 'YEXT', 'NWGL', 'EIC', 'FDFF', 'NWG', 'YMM', 'YORW', 'EHLS', 'YOU', 'YPF', 'EHI', 'EHGO', 'FBLG', 'FBIOP', 'FBIO', 'NVVEW', 'NVVE', 'FBGL', 'YRD', 'YSG', 'YUM', 'YUMC', 'YY', 'EXEEW', 'EXEEL', 'EGGQ', 'EGF', 'ESMV', 'NVNIW', 'NVNI', 'Z', 'ZBH', 'ESLAW', 'NVG', 'EFT', 'ZBRA', 'NVFY', 'NVDU', 'ZD', 'DYCQR', 'ZETA', 'ZEUS', 'DMAT', 'NVDS', 'ZG', 'ZGN', 'ZI', 'ZIM', 'ZION', 'ZIP', 'EFSI', 'DFGX', 'EFSCP', 'ZLAB', 'EFRA', 'ZM', 'DCOMP', 'ZNTL', 'DCOMG', 'ZS', 'ZTO', 'ZWS', 'NVDL', 'ZYME', 'DCAP', 'EFOI', 'C', 'CAVA', 'NVD', 'CYCC', 'CXSE', 'FBLA', 'NVRO', 'NVCT', 'RGNX', 'CUBWU', 'ABSI', 'AQN', 'CUBB', 'BKCH', 'CUBA', 'CRMLW', 'BLND', 'BUR', 'BWFG', 'CTS', 'DNUT', 'EQC', 'ETNB', 'NVAWW', 'KT', 'LMT', 'LNSR', 'NVA', 'NUWE', 'MPLX', 'MSFT', 'NUTX', 'COIG', 'CNCK', 'MTW', 'NUSB', 'NMR', 'PSX', 'NURO', 'RNST', 'SBSI', 'SMH', 'SMPL', 'CLNN']\n"
     ]
    }
   ],
   "source": [
    "# API call for Alpaca assets\n",
    "assets = alpaca.list_assets(status='active')  # Consider only active assets\n",
    "\n",
    "# All US exchanges (NASDAQ, NYSE)\n",
    "us_exchanges = ['NASDAQ', 'NYSE', 'AMEX']\n",
    "\n",
    "# Filter to company stocks only (Uppercase letters only, no numbers, periods, underscores, lowercase)\n",
    "stock_assets = [\n",
    "    asset for asset in assets\n",
    "    if asset.exchange in us_exchanges\n",
    "    and asset.tradable\n",
    "    and asset.status == 'active'\n",
    "    and asset.symbol.isalpha()\n",
    "    and asset.symbol.isupper()\n",
    "]\n",
    "\n",
    "stock_tickers = [asset.symbol for asset in stock_assets]\n",
    "\n",
    "print(f\"Fetched {len(stock_tickers)} company stock tickers from Alpaca (U.S. exchanges, no CUSIPs/ETFs/SPACs)!\")\n",
    "print(\"First 20 company stock tickers:\", stock_tickers[:20])\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test the fetch time for Alpaca"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fetching OHLC from 2002-01-01 to 2025-03-20 (~threshold: 1260 days)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Alpaca Download Progress:   6%|▌         | 3/50 [00:02<00:37,  1.25it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Skipped NXLIW (~629 < 1260 days)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Alpaca Download Progress:  10%|█         | 5/50 [00:04<00:30,  1.45it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Skipped NXL (~629 < 1260 days)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Alpaca Download Progress:  14%|█▍        | 7/50 [00:05<00:27,  1.55it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Skipped ELBM (~727 < 1260 days)\n",
      "Skipped ELAB (~332 < 1260 days)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Alpaca Download Progress:  22%|██▏       | 11/50 [00:07<00:16,  2.30it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Skipped IDAI (~787 < 1260 days)\n",
      "Skipped ICUCW (~1007 < 1260 days)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Alpaca Download Progress:  24%|██▍       | 12/50 [00:07<00:13,  2.74it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Skipped ICU (~1007 < 1260 days)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Alpaca Download Progress:  34%|███▍      | 17/50 [00:10<00:12,  2.69it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Skipped EKG (~751 < 1260 days)\n",
      "Skipped HTFC (~686 < 1260 days)\n",
      "Skipped HOVR (~493 < 1260 days)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Alpaca Download Progress:  36%|███▌      | 18/50 [00:10<00:09,  3.25it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Skipped NXGLW (~813 < 1260 days)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Alpaca Download Progress:  46%|████▌     | 23/50 [00:13<00:09,  2.76it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Skipped XMTR (~935 < 1260 days)\n",
      "Skipped GRDN (~120 < 1260 days)\n",
      "Skipped GDSTR (~735 < 1260 days)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Alpaca Download Progress:  50%|█████     | 25/50 [00:16<00:18,  1.34it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Skipped EIIA (~104 < 1260 days)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Alpaca Download Progress:  58%|█████▊    | 29/50 [00:18<00:13,  1.51it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Skipped XPEV (~1146 < 1260 days)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Alpaca Download Progress:  66%|██████▌   | 33/50 [00:21<00:09,  1.70it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Skipped EICC (~236 < 1260 days)\n",
      "Skipped NWTN (~1257 < 1260 days)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Alpaca Download Progress:  72%|███████▏  | 36/50 [00:22<00:06,  2.11it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Skipped FIVY (~63 < 1260 days)\n",
      "Skipped EICB (~411 < 1260 days)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Alpaca Download Progress:  76%|███████▌  | 38/50 [00:24<00:06,  1.91it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Skipped NWTG (~401 < 1260 days)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Alpaca Download Progress:  80%|████████  | 40/50 [00:25<00:05,  1.82it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Skipped EICA (~852 < 1260 days)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Alpaca Download Progress:  84%|████████▍ | 42/50 [00:26<00:04,  1.80it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Skipped NWGL (~382 < 1260 days)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Alpaca Download Progress:  88%|████████▊ | 44/50 [00:28<00:03,  1.78it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Skipped FDFF (~445 < 1260 days)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Alpaca Download Progress:  92%|█████████▏| 46/50 [00:29<00:02,  1.69it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Skipped YMM (~941 < 1260 days)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Alpaca Download Progress:  98%|█████████▊| 49/50 [00:31<00:00,  2.06it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Skipped EHLS (~243 < 1260 days)\n",
      "Skipped YOU (~935 < 1260 days)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Alpaca Download Progress: 100%|██████████| 50/50 [00:32<00:00,  1.53it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Fetched 48488 rows of stock data in 32.69 seconds.\n",
      "Processed 50 tickers, skipped 27 tickers.\n",
      "Processing time per ticker: 0.65 seconds. Estimated processing time for all stocks in the dataset: 78 minutes.\n",
      "\n",
      "Example Table Data:\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ticker</th>\n",
       "      <th>date</th>\n",
       "      <th>open</th>\n",
       "      <th>high</th>\n",
       "      <th>low</th>\n",
       "      <th>close</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>XHR</td>\n",
       "      <td>2016-01-04</td>\n",
       "      <td>15.04</td>\n",
       "      <td>15.2500</td>\n",
       "      <td>14.7400</td>\n",
       "      <td>14.95</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>XHR</td>\n",
       "      <td>2016-01-05</td>\n",
       "      <td>14.98</td>\n",
       "      <td>15.6500</td>\n",
       "      <td>14.9100</td>\n",
       "      <td>15.56</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>XHR</td>\n",
       "      <td>2016-01-06</td>\n",
       "      <td>15.35</td>\n",
       "      <td>15.6000</td>\n",
       "      <td>15.2901</td>\n",
       "      <td>15.41</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>XHR</td>\n",
       "      <td>2016-01-07</td>\n",
       "      <td>15.10</td>\n",
       "      <td>15.2800</td>\n",
       "      <td>14.6900</td>\n",
       "      <td>14.69</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>XHR</td>\n",
       "      <td>2016-01-08</td>\n",
       "      <td>14.74</td>\n",
       "      <td>14.7400</td>\n",
       "      <td>14.2500</td>\n",
       "      <td>14.29</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>XHR</td>\n",
       "      <td>2016-01-11</td>\n",
       "      <td>14.32</td>\n",
       "      <td>14.6700</td>\n",
       "      <td>14.2500</td>\n",
       "      <td>14.55</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>XHR</td>\n",
       "      <td>2016-01-12</td>\n",
       "      <td>14.68</td>\n",
       "      <td>14.8000</td>\n",
       "      <td>14.4100</td>\n",
       "      <td>14.65</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>XHR</td>\n",
       "      <td>2016-01-13</td>\n",
       "      <td>14.67</td>\n",
       "      <td>14.7100</td>\n",
       "      <td>13.9100</td>\n",
       "      <td>13.97</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>XHR</td>\n",
       "      <td>2016-01-14</td>\n",
       "      <td>14.00</td>\n",
       "      <td>14.1500</td>\n",
       "      <td>13.5300</td>\n",
       "      <td>13.93</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>XHR</td>\n",
       "      <td>2016-01-15</td>\n",
       "      <td>13.53</td>\n",
       "      <td>13.5900</td>\n",
       "      <td>12.8130</td>\n",
       "      <td>12.96</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>XHR</td>\n",
       "      <td>2016-01-19</td>\n",
       "      <td>13.07</td>\n",
       "      <td>13.1700</td>\n",
       "      <td>12.6100</td>\n",
       "      <td>12.73</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>XHR</td>\n",
       "      <td>2016-01-20</td>\n",
       "      <td>12.54</td>\n",
       "      <td>13.2000</td>\n",
       "      <td>12.1001</td>\n",
       "      <td>13.01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>XHR</td>\n",
       "      <td>2016-01-21</td>\n",
       "      <td>13.03</td>\n",
       "      <td>13.9600</td>\n",
       "      <td>12.9500</td>\n",
       "      <td>13.64</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>XHR</td>\n",
       "      <td>2016-01-22</td>\n",
       "      <td>13.85</td>\n",
       "      <td>14.0100</td>\n",
       "      <td>13.4600</td>\n",
       "      <td>13.68</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>XHR</td>\n",
       "      <td>2016-01-25</td>\n",
       "      <td>13.64</td>\n",
       "      <td>13.9600</td>\n",
       "      <td>13.3001</td>\n",
       "      <td>13.37</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>XHR</td>\n",
       "      <td>2016-01-26</td>\n",
       "      <td>13.46</td>\n",
       "      <td>14.1700</td>\n",
       "      <td>13.4201</td>\n",
       "      <td>14.17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>XHR</td>\n",
       "      <td>2016-01-27</td>\n",
       "      <td>14.07</td>\n",
       "      <td>14.2700</td>\n",
       "      <td>13.8150</td>\n",
       "      <td>13.93</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>XHR</td>\n",
       "      <td>2016-01-28</td>\n",
       "      <td>14.05</td>\n",
       "      <td>14.3100</td>\n",
       "      <td>14.0000</td>\n",
       "      <td>14.01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>XHR</td>\n",
       "      <td>2016-01-29</td>\n",
       "      <td>14.08</td>\n",
       "      <td>14.6500</td>\n",
       "      <td>14.0800</td>\n",
       "      <td>14.63</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>XHR</td>\n",
       "      <td>2016-02-01</td>\n",
       "      <td>14.55</td>\n",
       "      <td>14.5500</td>\n",
       "      <td>14.0900</td>\n",
       "      <td>14.20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>XHR</td>\n",
       "      <td>2016-02-02</td>\n",
       "      <td>13.98</td>\n",
       "      <td>14.1000</td>\n",
       "      <td>13.6100</td>\n",
       "      <td>13.64</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>XHR</td>\n",
       "      <td>2016-02-03</td>\n",
       "      <td>13.76</td>\n",
       "      <td>13.9300</td>\n",
       "      <td>13.3100</td>\n",
       "      <td>13.85</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>XHR</td>\n",
       "      <td>2016-02-04</td>\n",
       "      <td>13.82</td>\n",
       "      <td>14.2950</td>\n",
       "      <td>13.8050</td>\n",
       "      <td>14.15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>XHR</td>\n",
       "      <td>2016-02-05</td>\n",
       "      <td>14.09</td>\n",
       "      <td>14.2700</td>\n",
       "      <td>13.8900</td>\n",
       "      <td>13.90</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>XHR</td>\n",
       "      <td>2016-02-08</td>\n",
       "      <td>13.76</td>\n",
       "      <td>13.9900</td>\n",
       "      <td>13.3700</td>\n",
       "      <td>13.90</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>XHR</td>\n",
       "      <td>2016-02-09</td>\n",
       "      <td>13.71</td>\n",
       "      <td>14.1400</td>\n",
       "      <td>13.6400</td>\n",
       "      <td>13.80</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>XHR</td>\n",
       "      <td>2016-02-10</td>\n",
       "      <td>13.89</td>\n",
       "      <td>14.3400</td>\n",
       "      <td>13.8100</td>\n",
       "      <td>13.96</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>XHR</td>\n",
       "      <td>2016-02-11</td>\n",
       "      <td>13.65</td>\n",
       "      <td>13.8451</td>\n",
       "      <td>13.3300</td>\n",
       "      <td>13.57</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>XHR</td>\n",
       "      <td>2016-02-12</td>\n",
       "      <td>13.69</td>\n",
       "      <td>14.1200</td>\n",
       "      <td>13.6200</td>\n",
       "      <td>13.98</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>XHR</td>\n",
       "      <td>2016-02-16</td>\n",
       "      <td>14.10</td>\n",
       "      <td>14.4900</td>\n",
       "      <td>13.7000</td>\n",
       "      <td>14.39</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   ticker        date   open     high      low  close\n",
       "0     XHR  2016-01-04  15.04  15.2500  14.7400  14.95\n",
       "1     XHR  2016-01-05  14.98  15.6500  14.9100  15.56\n",
       "2     XHR  2016-01-06  15.35  15.6000  15.2901  15.41\n",
       "3     XHR  2016-01-07  15.10  15.2800  14.6900  14.69\n",
       "4     XHR  2016-01-08  14.74  14.7400  14.2500  14.29\n",
       "5     XHR  2016-01-11  14.32  14.6700  14.2500  14.55\n",
       "6     XHR  2016-01-12  14.68  14.8000  14.4100  14.65\n",
       "7     XHR  2016-01-13  14.67  14.7100  13.9100  13.97\n",
       "8     XHR  2016-01-14  14.00  14.1500  13.5300  13.93\n",
       "9     XHR  2016-01-15  13.53  13.5900  12.8130  12.96\n",
       "10    XHR  2016-01-19  13.07  13.1700  12.6100  12.73\n",
       "11    XHR  2016-01-20  12.54  13.2000  12.1001  13.01\n",
       "12    XHR  2016-01-21  13.03  13.9600  12.9500  13.64\n",
       "13    XHR  2016-01-22  13.85  14.0100  13.4600  13.68\n",
       "14    XHR  2016-01-25  13.64  13.9600  13.3001  13.37\n",
       "15    XHR  2016-01-26  13.46  14.1700  13.4201  14.17\n",
       "16    XHR  2016-01-27  14.07  14.2700  13.8150  13.93\n",
       "17    XHR  2016-01-28  14.05  14.3100  14.0000  14.01\n",
       "18    XHR  2016-01-29  14.08  14.6500  14.0800  14.63\n",
       "19    XHR  2016-02-01  14.55  14.5500  14.0900  14.20\n",
       "20    XHR  2016-02-02  13.98  14.1000  13.6100  13.64\n",
       "21    XHR  2016-02-03  13.76  13.9300  13.3100  13.85\n",
       "22    XHR  2016-02-04  13.82  14.2950  13.8050  14.15\n",
       "23    XHR  2016-02-05  14.09  14.2700  13.8900  13.90\n",
       "24    XHR  2016-02-08  13.76  13.9900  13.3700  13.90\n",
       "25    XHR  2016-02-09  13.71  14.1400  13.6400  13.80\n",
       "26    XHR  2016-02-10  13.89  14.3400  13.8100  13.96\n",
       "27    XHR  2016-02-11  13.65  13.8451  13.3300  13.57\n",
       "28    XHR  2016-02-12  13.69  14.1200  13.6200  13.98\n",
       "29    XHR  2016-02-16  14.10  14.4900  13.7000  14.39"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Alpaca Sample: None\n"
     ]
    }
   ],
   "source": [
    "years_back = 5  # Number of years of historical data required\n",
    "start_date = \"2002-01-01\"  # Start date for data fetching\n",
    "end_date = (datetime.now() - timedelta(days=1)).strftime(\"%Y-%m-%d\")  # End date (yesterday)\n",
    "trading_days_back = years_back * 252  # Approximate number of trading days per year (252)\n",
    "\n",
    "print(f\"Fetching OHLC from {start_date} to {end_date} (~threshold: {trading_days_back} days)\")\n",
    "\n",
    "# Initialize dataframe and performance tracking variables\n",
    "alpaca_df = pd.DataFrame()\n",
    "start_time = time.time()\n",
    "missing_data_count = 0  # Counter for tickers with no data\n",
    "not_enough_time_count = 0  # Counter for tickers with insufficient data\n",
    "processed_ticker_count = 0  # Counter for processed tickers\n",
    "subset_size = 175  # Number of tickers to process in this run\n",
    "subset_tickers = stock_tickers[:subset_size]  # Select the first 50 tickers\n",
    "\n",
    "# Loop through each ticker to fetch historical stock data from Alpaca\n",
    "for ticker in tqdm(subset_tickers, desc=\"Alpaca Download Progress\"):\n",
    "    try:\n",
    "        processed_ticker_count += 1  # Increment the processed ticker counter\n",
    "        bars = alpaca.get_bars(ticker, \"1Day\", start_date, end_date).df  # Fetch daily OHLC data\n",
    "\n",
    "        # Check if any data was retrieved\n",
    "        if not bars.empty:\n",
    "            # Extract relevant OHLC data and reset the DataFrame index\n",
    "            df = bars[['open', 'high', 'low', 'close']].reset_index()\n",
    "\n",
    "            # Check if retrieved data covers the required number of years\n",
    "            if len(df) < trading_days_back:\n",
    "                missing_data_count += 1\n",
    "                not_enough_time_count += 1\n",
    "                print(f\"Not enough trading days. Skipped {ticker} (~{len(df)} < {trading_days_back} days)\")\n",
    "                continue\n",
    "\n",
    "            # Add ticker and formatted date columns for clarity\n",
    "            df['ticker'] = ticker\n",
    "            df['date'] = df['timestamp'].dt.strftime(\"%Y-%m-%d\")\n",
    "\n",
    "            # Reorder columns\n",
    "            df = df[['ticker', 'date', 'open', 'high', 'low', 'close']]\n",
    "\n",
    "            # Append this ticker's data to the main DataFrame\n",
    "            alpaca_df = pd.concat([alpaca_df, df])\n",
    "        else:\n",
    "            # If no data was retrieved, increment the missing data counter\n",
    "            missing_data_count += 1\n",
    "            print(f\"No data for {ticker}\")\n",
    "\n",
    "        # Wait briefly to prevent API rate limiting\n",
    "        time.sleep(1)\n",
    "\n",
    "    except Exception as e:\n",
    "        # Handle and log any exceptions during data retrieval\n",
    "        print(f\"Error for {ticker}: {e}\")\n",
    "        time.sleep(1)\n",
    "\n",
    "# Calculate total processing time and performance metrics\n",
    "total_seconds = time.time() - start_time\n",
    "seconds_per_ticker = round((total_seconds / len(subset_tickers)), 2)\n",
    "estimated_total_time = round(seconds_per_ticker * len(stock_tickers) / 60)\n",
    "\n",
    "# Output performance summary and sample data\n",
    "print(f\"\\nFetched {len(alpaca_df)} rows of stock data in {total_seconds:.2f} seconds.\")\n",
    "print(f\"Processed {processed_ticker_count} tickers, missing {missing_data_count} tickers, {not_enough_time_count} tickers did not have enough time.\")\n",
    "print(f\"Processing time per ticker: {seconds_per_ticker:.2f} seconds. Estimated processing time for all stocks in the dataset: {estimated_total_time} minutes.\")\n",
    "print(\"\\nExample Table Data:\\n\")\n",
    "print(\"Alpaca Sample:\", display(alpaca_df.head(30)))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "aaron_dev",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
